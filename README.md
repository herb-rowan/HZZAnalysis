# **Scalable Data Analysis of Higgs Boson Decay Using Kubernetes**

This project demonstrates a containerized, distributed system for analyzing ATLAS Open Data, specifically the \( H \to ZZ \to 4\ell \) decay channel. The system is implemented using Docker, RabbitMQ, and Kubernetes to ensure scalability, fault tolerance, and reproducibility.

---

## **Table of Contents**
1. [Overview](#overview)  
2. [System Requirements](#system-requirements)  
3. [Setup Instructions](#setup-instructions)  
4. [Running the Program](#running-the-program)  
5. [Monitoring and Troubleshooting](#monitoring-and-troubleshooting)  
6. [Accessing Results](#accessing-results)  
7. [Test Scalability with Multiple Virtual Nodes](#test-scalability-with-multiple-virtual-nodes)  
8. [Cleaning Up](#cleaning-up)  
9. [Future Enhancements](#future-enhancements)  

---

## **Overview**
This program analyzes Higgs boson decays using a distributed pipeline:
1. **Data Acquisition**: Downloads experimental and Monte Carlo datasets.  
2. **Preprocessing**: Selects events, reconstructs invariant masses, and identifies \( H \to ZZ \to 4\ell \) events.  
3. **Monte Carlo Simulation**: Processes MC signal and background datasets.  
4. **Aggregation**: Combines outputs into unified datasets.  
5. **Visualization**: Produces histograms showing invariant mass distributions.

The system uses Kubernetes to orchestrate services, RabbitMQ for inter-service communication, and Persistent Volumes for shared data.

---

## **System Requirements**
Before running this program, ensure you have the following:
- **Docker**: Version 20.10+  
- **Minikube**: Version 1.29+ (or any Kubernetes cluster)  
- **kubectl**: Version 1.26+  
- **Python**: Version 3.10+ (optional for local debugging)  

---

## **Setup Instructions**

### **1. Clone the Repository**
Clone the project to your local machine:
```bash
git clone https://github.com/herb-rowan/HZZAnalysis.git
cd higgs-analysis
```

---

### **2. Start Minikube**
Start your local Kubernetes cluster using Minikube with multiple nodes to simulate a distributed environment:
```bash
minikube start --nodes=3
```

---

### **3. Enable Minikube Docker Environment**
Switch to the Minikube Docker environment to build images locally:
```bash
eval $(minikube docker-env)
```

---

### **4. Build Docker Image**
Build the Docker image for the project:
```bash
docker build -t hzzanalysis:latest .
```

Verify the image was built:
```bash
docker images
```

---

### **5. Deploy the System**
Apply the Kubernetes configurations to deploy the program:

#### Persistent Volume
Create Persistent Volumes and Claims for shared data storage:
```bash
kubectl apply -f persistent-volume.yaml
```

#### RabbitMQ
Deploy RabbitMQ for message queuing:
```bash
kubectl apply -f rabbitmq-deployment.yaml
kubectl apply -f rabbitmq-service.yaml
```

#### Application Services
Deploy each stage of the pipeline:
```bash
kubectl apply -f data-acquisition-deployment.yaml
kubectl apply -f data-processing-deployment.yaml
kubectl apply -f aggregation-deployment.yaml
kubectl apply -f visualization-deployment.yaml
```

Verify all Pods are running:
```bash
kubectl get pods
```

---

## **Running the Program**

Once all Pods are running, the pipeline will automatically execute the following steps:
1. Download data files.
2. Process and analyze events.
3. Simulate signal and background.
4. Aggregate the results.
5. Generate visualizations.

---

## **Monitoring and Troubleshooting**

### **1. Monitor Pod Status**
Check the status of all Pods:
```bash
kubectl get pods
```

---

### **2. View Logs**
To see the logs of a specific Pod:
```bash
kubectl logs <pod-name>
```

Example:
```bash
kubectl logs data-acquisition-<pod-id>
```

---

### **3. Debugging Failed Pods**
If a Pod is failing, describe it for more details:
```bash
kubectl describe pod <pod-name>
```

---

### **4. Access RabbitMQ Dashboard**
RabbitMQ provides a web interface for monitoring queues:
1. Get the Minikube IP:
   ```bash
   minikube service rabbitmq-service --url
   ```
2. Access RabbitMQ Management at `<Minikube-IP>:15672`.  
3. Use the default credentials:
   - **Username**: guest  
   - **Password**: guest  

---

## **Accessing Results**

### **1. Download Histogram**
The histogram generated by the visualization service will be saved in `/app/output/histogram.png` inside the container.

Copy the histogram to your local machine:
```bash
POD_NAME=$(kubectl get pods -l app=visualization -o jsonpath='{.items[0].metadata.name}')
kubectl cp $POD_NAME:/app/output/histogram.png ./output/histogram.png
```

Verify the file:
```bash
ls ./output/histogram.png
```

---

### **2. Retrieve Intermediate Outputs**
Intermediate results (e.g., Parquet files) are stored in the shared Persistent Volume. Exec into any Pod to explore:
```bash
kubectl exec -it <pod-name> -- /bin/sh
ls /app/data
```

---

## **Test Scalability with Multiple Virtual Nodes**

### **1. Set Up Minikube with Multiple Nodes**
Minikube allows you to run a Kubernetes cluster with multiple nodes. To simulate a distributed environment:

```bash
minikube start --nodes=3
```

This starts a Kubernetes cluster with 3 virtual nodes. You can scale your application and test how it behaves across multiple nodes.

---

### **2. Verify Node Availability**
Check the status of the nodes in the cluster:

```bash
kubectl get nodes
```

You should see the nodes listed, with one of them being the master node and the others being worker nodes.

---

### **3. Scale Deployments Across Nodes**
You can scale your deployments across the nodes:
```bash
kubectl scale deployment data-acquisition --replicas=3
kubectl scale deployment data-processing --replicas=3
kubectl scale deployment visualization --replicas=3
```

After scaling, use the following command to check where the Pods are scheduled:

```bash
kubectl get pods -o wide
```

The Pods will be distributed across the available nodes.

---

### **4. Load Testing**
To simulate real-world traffic and test how the application handles load, you can use a tool like `hey`:

1. Find the Minikube service URL:
   ```bash
   minikube service <service-name> --url
   ```

2. Run `hey` to generate load:
   ```bash
   hey -z 60s -c 10 http://<minikube-ip>:<service-port>
   ```

---

## **Cleaning Up**

After running and testing the program, you can clean up the resources by deleting the deployments and stopping Minikube:

### **1. Clean Up Kubernetes Resources**
To delete all resources:
```bash
kubectl delete deployment --all
kubectl delete svc --all
kubectl delete pvc --all
kubectl delete pv --all
```

### **2. Stop Minikube**
Stop Minikube when you're done:
```bash
minikube stop
```

---

## **Future Enhancements**
This system is designed for scalability and can be extended to:
1. Run on cloud-based Kubernetes clusters for large-scale data analysis.
2. Implement RabbitMQ clustering for improved task distribution.
3. Use cloud-based storage (e.g., AWS S3) for faster data I/O.

